{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50fc376d",
   "metadata": {},
   "source": [
    "# Potential evaporation from reanalysis data\n",
    "\n",
    "A recent study (Singer et al., 2021) developed an hourly PET dataset (hPET) for the global land surface at 0.1 degree spatial resolution, based on the output from ERA5-land reanalysis dataset (ERA5 Atmospheric Reanalysis Climate Data Guide, n.d.). The PET was calculated based on the standard method for computing reference evapotranspiration developed by the Food and Agriculture Organization (FAO).\n",
    "\n",
    "\n",
    "Provided Python script by the authors for easy access of the datasets: (https://github.com/Dagmawi-TA/hPET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0063a1e1",
   "metadata": {},
   "source": [
    "### NOTE: This code is not yet customized for the study sites of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dde249f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from netCDF4 import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6025e9b",
   "metadata": {},
   "source": [
    "Note: Install netCDF4 via Terminal/ powershell:\n",
    "`conda install -c conda-forge netCDF4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cb5eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper(startyear,endyear,latmin,latmax,lonmin,lonmax,regionname,t_resolution,output_path):\n",
    "    \"\"\"\n",
    "    This is a wrapper function to run for downloading hPET and dPET data.\n",
    "    All the arguments need to be given at the end of the script before running\n",
    "    the script.\n",
    "    :param startyear: the begging year to start the data download (min = 1981, max = 2019)\n",
    "    :param endyear: the last year of data to be  downloaded (min = 1981, max = 2019)\n",
    "    :param latmin: the minimum latitude value of the region (float)\n",
    "    :param latmax: the maximum latitude value of the region (float)\n",
    "    :param lonmin: the minimum longitude value of the region (float)\n",
    "    :param lonmax: the maximum longitude value of the region (float)\n",
    "    :param regionname: name of the region (it could be any name the user wants) (string)\n",
    "    :param t_resolution: the time resolution to be downloaded (daily or hourly)\n",
    "    :param output_path:  the file path to store the downloaded data (string)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    if t_resolution == 'daily':\n",
    "        datapath = '/bp1store/geog-tropical/data/ERA-Land/driving_data/global_pet/daily_pet/'\n",
    "    elif t_resolution == 'hourly':\n",
    "        datapath = '/bp1store/geog-tropical/data/ERA-Land/driving_data/global_pet/hourly_pet/'\n",
    "    else:\n",
    "        raise ValueError(\"t_resolution is wrong please write 'daily' or 'hourly'\")\n",
    "\n",
    "    # set up the year array loop through each year to download the data\n",
    "    years = np.arange(startyear,endyear+1)\n",
    "    for y in range(0,len(years)):\n",
    "        year=int(years[y])\n",
    "        region_extract(datapath,year,latmin,latmax,lonmin,lonmax,regionname,t_resolution,output_path)\n",
    "        print(year)\n",
    "\n",
    "\n",
    "\n",
    "def region_extract(datapath,year,latmin,latmax,lonmin,lonmax,regionname,t_resolution,output_path):\n",
    "    \"\"\"\n",
    "    This function extract the data from the global hPET and dPET file and write a new\n",
    "    netCDF file with a file name <year>_<t_resolution>_pet_<regionname>.nc in the output_path\n",
    "    provided.\n",
    "    :param datapath: the file path where the hPET data is stored (url)\n",
    "    :param year: the year for which data is going to be downloaded (integer)\n",
    "    :param latmin: the minimum latitude value (float)\n",
    "    :param latmax: the maximum latitude value (float)\n",
    "    :param lonmin: the minimum longitude value (float)\n",
    "    :param lonmax: the maximum longitude value (float)\n",
    "    :param regionname: name of the region (it could be any name the user wants) (string)\n",
    "    :param t_resolution: the time resolution to be downloaded (daily or hourly)\n",
    "    :param output_path:  the file path to store the downloaded data (string)\n",
    "    :return: hPET or dPET data in a netCDF file\n",
    "    \"\"\"\n",
    "\n",
    "    if t_resolution == 'daily':\n",
    "        fname = '_daily_pet.nc'\n",
    "    elif t_resolution == 'hourly':\n",
    "        fname = '_hourly_pet.nc'\n",
    "    else:\n",
    "        raise ValueError(\"t_resolution is wrong please write 'daily' or 'hourly'\")\n",
    "\n",
    "    pet_hr = Dataset(datapath + str(year) + fname)\n",
    "    lats = pet_hr.variables['latitude'][:]\n",
    "    lons = pet_hr.variables['longitude'][:]\n",
    "    \n",
    "    # extract the min and max index\n",
    "    latminind, lonminind = nearest_point(latmin, lonmin, lats, lons)\n",
    "    latmaxind, lonmaxind = nearest_point(latmax, lonmax, lats, lons)\n",
    " \n",
    "    # read athe data pet\n",
    "    reg_data=pet_hr.variables['pet'][:, latmaxind:latminind, lonminind:lonmaxind]  \n",
    "    \n",
    "    newlats=lats[latmaxind:latminind]\n",
    "    newlons=lons[lonminind:lonmaxind]\n",
    "\n",
    "    filename=output_path+str(year)+'_'+t_resolution+'_pet_'+regionname+'.nc'\n",
    "    nc_write(reg_data, newlats, newlons, filename)\n",
    "\n",
    "    return None\n",
    "    \n",
    "\n",
    "def nearest_point(lat_var, lon_var, lats, lons):\n",
    "    \"\"\"\n",
    "    This function identify the nearest grid location index for a specific lat-lon\n",
    "    point.\n",
    "    :param lat_var: the latitude\n",
    "    :param lon_var: the longitude\n",
    "    :param lats: all available latitude locations in the data\n",
    "    :param lons: all available longitude locations in the data\n",
    "    :return: the lat_index and lon_index\n",
    "    \"\"\"\n",
    "    # this part is to handle if lons are givn 0-360 or -180-180\n",
    "    if any(lons > 180.0) and (lon_var < 0.0):\n",
    "        lon_var = lon_var + 360.0\n",
    "    else:\n",
    "        lon_var = lon_var\n",
    "        \n",
    "    lat = lats\n",
    "    lon = lons\n",
    "\n",
    "    if lat.ndim == 2:\n",
    "        lat = lat[:, 0]\n",
    "    else:\n",
    "        pass\n",
    "    if lon.ndim == 2:\n",
    "        lon = lon[0, :]\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    index_a = np.where(lat >= lat_var)[0][-1]\n",
    "    index_b = np.where(lat <= lat_var)[0][-1]\n",
    "\n",
    "    if abs(lat[index_a] - lat_var) >= abs(lat[index_b] - lat_var):\n",
    "        index_lat = index_b\n",
    "    else:\n",
    "        index_lat = index_a\n",
    "\n",
    "    index_a = np.where(lon >= lon_var)[0][0]\n",
    "    index_b = np.where(lon <= lon_var)[0][0]\n",
    "    if abs(lon[index_a] - lon_var) >= abs(lon[index_b] - lon_var):\n",
    "        index_lon = index_b\n",
    "    else:\n",
    "        index_lon = index_a\n",
    "\n",
    "    return index_lat, index_lon\n",
    "\n",
    "\n",
    "def nc_write(pet, lat, lon, filename):\n",
    "    \"\"\"\n",
    "    this function write the PET on a netCDF file.\n",
    "    :param: pet: PET (time,lat,lon)\n",
    "    :param: lat: latitude\n",
    "    :param:lon: longitude\n",
    "    :param:filename: the file name to write the values with .nc extension\n",
    "    :return:  produce a netCDF file in the same directory.\n",
    "    \"\"\"\n",
    "\n",
    "    ds = Dataset(filename, mode='w', format='NETCDF4_CLASSIC')\n",
    "\n",
    "    time = ds.createDimension('time', None)\n",
    "    latitude = ds.createDimension('latitude', len(lat))\n",
    "    longitude = ds.createDimension('longitude', len(lon))\n",
    "   \n",
    "    time = ds.createVariable('time', np.float32, ('time',))\n",
    "    latitude = ds.createVariable('latitude', np.float32, ('latitude',))\n",
    "    longitude = ds.createVariable('longitude', np.float32, ('longitude',))\n",
    "    pet_val = ds.createVariable('pet', 'f4', ('time','latitude','longitude'))\n",
    "   \n",
    "    time.units = 'days since 1981-01-01'\n",
    "    time.calendar = 'proleptic_gregorian'\n",
    "    time[:] = np.arange(pet.shape[0])\n",
    "    latitude[:] = lat\n",
    "    longitude [:] = lon\n",
    "    pet_val[:,:,:] = pet\n",
    "    ds.close()\n",
    "    \n",
    "    return None    \n",
    "##### ---------------------------######\n",
    "# to extract data please fill the arguments in the function and run the script.\n",
    "if __name__ == '__main__':\n",
    "    # example (please change these values to your specification)\n",
    "    # input arguments\n",
    "    startyear = 1981\n",
    "    endyear = 1983\n",
    "    latmin=-0.7\n",
    "    latmax=1.7\n",
    "    lonmin=35.8\n",
    "    lonmax=38.4\n",
    "    regionname='kenya'\n",
    "    t_resolution ='daily'\n",
    "    output_path = '/home/fp20123/andres_kenya/'\n",
    "    # run script\n",
    "    wrapper(startyear,endyear,latmin,latmax,lonmin,lonmax,regionname,t_resolution,output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
